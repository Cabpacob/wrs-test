## ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ ì„ë² ë”©ì„ ì´ìš©í•œ ì¶”ì²œ ì‹œìŠ¤í…œ ë§Œë“¤ê¸°(Building a Recommendation System Using Neural Network Embeddings)
ë”¥ëŸ¬ë‹ê³¼ ìœ„í‚¤í”¼ë””ì•„ë¥¼ ì´ìš©í•´ì„œ ì±… ì¶”ì²œ ì‹œìŠ¤í…œì„ ì–´ë–»ê²Œ ë§Œë“¤ ìˆ˜ ìˆì„ê¹Œ? ğŸ¤” ğŸ¤” (How to use deep learning and Wikipedia to create a book recommendation system)
[ì›ë¬¸ ë§í¬](https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9)
> ì´ íŠœí† ë¦¬ì–¼ì€ ìœ„í‚¤í”¼ë””ì•„ì— ìˆëŠ” ì±…ì— ëŒ€í•œ ì •ë³´ì™€ ìœ„í‚¤í”¼ë””ì•„ ë‚´ìš©ì— ìˆëŠ” ë‹¤ë¥¸ ì±…ë“¤ì˜ ë§í¬ë“¤ì„ ì„ë² ë”©í•œ í›„, ì½”ì‚¬ì¸ ìœ ì‚¬ë„(cosine similarity)ë¥¼ ì´ìš©í•´ ë¹„ìŠ·í•œ ì±…ì„ ì¶”ì²œí•©ë‹ˆë‹¤.

* Keras
* Recommendation System
* Neural Network
* Embedding

### Introduction

ë”¥ëŸ¬ë‹ì€ [ë†€ë¼ìš´ ì¼](https://blog.statsbot.co/deep-learning-achievements-4c563e034257?gi=f0d6d88ccb09)ì„ í•  ìˆ˜ ìˆì§€ë§Œ, ì¢…ì¢… ê·¸ ìš©ë„ëŠ” [í•™ìˆ ì§€](https://arxiv.org/abs/1301.3781)ì— ê°€ë ¤ì§€ê±°ë‚˜ ëŒ€ê¸°ì—…ì—ë§Œ ì œê³µë˜ëŠ” [ì»´í“¨íŒ… ìì›](https://dawn.cs.stanford.edu/benchmark/ImageNet/train.html)ì„ ìš”êµ¬í•©ë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ , ê³ ê¸‰ í•™ìœ„ë¥¼ ìš”êµ¬í•˜ì§€ ì•ŠëŠ” ê°œì¸ìš© ì»´í“¨í„°ì—ì„œ í•  ìˆ˜ ìˆëŠ” ë”¥ëŸ¬ë‹ ì–´í”Œë¦¬ì¼€ì´ì…˜ë“¤ì´ ìˆìŠµë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì—ì„œ ìš°ë¦¬ëŠ” ì‹ ê²½ë§ ì„ë² ë”©(neural network embeddings)ì„ ì‚¬ìš©í•˜ì—¬ ì±…ì— ê´€í•œ ëª¨ë“  ìœ„í‚¤í”¼ë””ì•„ ê¸°ì‚¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì±… ì¶”ì²œ ì‹œìŠ¤í…œì„ ë§Œë“œëŠ” ë°©ë²•ì„ ì´ì•¼ê¸°í•  ê²ƒì…ë‹ˆë‹¤.

ìš°ë¦¬ì˜ ì¶”ì²œ ì‹œìŠ¤í…œì€ ìœ ì‚¬í•œ(similarity) ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ë¡œ ì—°ê²°ë˜ëŠ” ì±…ë“¤ì´ ì„œë¡œ ë¹„ìŠ·í•˜ë‹¤ëŠ” ìƒê°ì„ ë°”íƒ•ìœ¼ë¡œ ë§Œë“¤ì–´ì§ˆ ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ìœ ì‚¬ë„ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆê³ , ë”°ë¼ì„œ ì‹ ê²½ë§ì„ ì´ìš©í•˜ì—¬ ì±…ê³¼ ìœ„í‚¤í”¼ë””ì•„ ë§í¬ë¥¼ ì„ë² ë”©í•˜ëŠ” ê²ƒì„ ë°°ì›€ìœ¼ë¡œì¨ ì¶”ì²œ ì‹œìŠ¤í…œì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìµœì¢… ê²°ê³¼ëŠ” íš¨ê³¼ì ì¸ ì¶”ì²œ ì‹œìŠ¤í…œì´ë©° ë”¥ëŸ¬ë‹ì˜ ì‹¤ì§ˆì ì¸ ì‚¬ìš©ì…ë‹ˆë‹¤. ğŸ˜Š



![cosine_distance_of_books](130_1.png)  

figure1 : ìŠ¤í‹°ë¸ í˜¸í‚¹ì˜ A Brief History of Time ë¼ëŠ” ì±…ê³¼ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ì±…ë“¤*



ì´ í”„ë¡œì íŠ¸ì˜ ì „ì²´ ì½”ë“œëŠ” GitHubì—ì„œ [Jupyter ë…¸íŠ¸ë¶](https://github.com/WillKoehrsen/wikipedia-data-science/blob/master/notebooks/Book%20Recommendation%20System.ipynb)ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ GPUê°€ ì—†ë‹¤ë©´ GPUë¡œ ì‹ ê²½ë§ì„ ë¬´ë£Œë¡œ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆëŠ” [Kaggleì˜ ë…¸íŠ¸ë¶](https://www.kaggle.com/willkoehrsen/neural-network-embedding-recommendation-system)ë„ ìˆìŠµë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì€ [ì´ì „ íŠœí† ë¦¬ì–¼](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526)ì—ì„œ ë‹¤ë£¨ì—ˆë˜ ì‹ ê²½ë§ ê°œë…ê³¼ í•¨ê»˜ ì ìš©í•˜ëŠ” ê²ƒì— ì´ˆì ì„ ë§ì¶œ ê²ƒì…ë‹ˆë‹¤. (ìš°ë¦¬ê°€ ì‚¬ìš©í•  ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë°©ë²•ì€ â€“ [all book articles on Wikipedia](https://towardsdatascience.com/wikipedia-data-science-working-with-the-worlds-largest-encyclopedia-c08efbac5f5c) - ì´ íŠœí† ë¦¬ì–¼ì„ ë³´ì„¸ìš”.)

ì´ í”„ë¡œì íŠ¸ëŠ” [ë”¥ëŸ¬ë‹ ì¿¡ë¶](http://shop.oreilly.com/product/0636920097471.do)ì—ì„œ ì±„ìš©í–ˆëŠ”ë°, ë”¥ëŸ¬ë‹ì˜ ì‹¤ì œ ì˜ˆë¥¼ ë³´ì—¬ì£¼ëŠ” í›Œë¥­í•œ [ì±…](https://github.com/DOsinga/deep_learning_cookbook)ì…ë‹ˆë‹¤. ğŸ‘




### ì‹ ê²½ë§ ì„ë² ë”© (Neural Network Embeddings)

ì„ë² ë”©ì€ ì´ì‚°í˜• ë³€ìˆ˜ë¥¼ ì—°ì† ë²¡í„°ë¡œ ë‚˜íƒ€ë‚´ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì›-í•« ì¸ì½”ë”©ê³¼ ê°™ì€ ì¸ì½”ë”© ë°©ë²•ê³¼ ëŒ€ì¡°ì ìœ¼ë¡œ ì‹ ê²½ë§ ì„ë² ë”©ì€ ì €ì°¨ì›ì´ë©° í•™ìŠµì„ í•´ì•¼í•©ë‹ˆë‹¤. ì¦‰, ì„ë² ë”© ê³µê°„ì— ì„œë¡œ ìœ ì‚¬í•œ ì‹¤ì²´ë¥¼ ì„œë¡œ ê°€ê¹ê²Œ ë°°ì¹˜í•œë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.

ì„ë² ë”©ì„ í•˜ê¸°ìœ„í•´ì„œ, ìš°ë¦¬ëŠ” ì‹ ê²½ë§ ëª¨ë¸ê³¼ ì§€ë„í•™ìŠµ(supervised learning) ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤. ìš°ë¦¬ ë„¤íŠ¸ì›Œí¬ì˜ ìµœì¢… ê²°ê³¼ëŠ” ê°ê°ì˜ ì±…ë“¤ì„ 50ê°œì˜ ì—°ì†ëœ ìˆ«ì ë²¡í„°ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒì´ ë  ê²ƒì…ë‹ˆë‹¤.

ì„ë² ë”© ìì²´ì—ëŠ” ê·¸ë‹¤ì§€ í¥ë¯¸ë¡œìš¸ ê²ƒì´ ì—†ìŠµë‹ˆë‹¤. ê·¸ì € ë²¡í„°ë“¤ì¼ ë¿ì´ì—ìš”. í•˜ì§€ë§Œ ì„ë² ë”©ì„ ì•„ë˜ ì„¸ê°€ì§€ ëª©ì ì„ ìœ„í•´ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. ì„ë² ë”© ê³µê°„ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒ(nearest neighbor) ì°¾ê¸°
2. ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì— ëŒ€í•œ ì…ë ¥ì£¼ê¸°
3. ì €ì°¨ì› ì‹œê°í™”í•˜ê¸°

> ìœ„ì—ì„œ **ê°€ê¹Œìš´ ì´ì›ƒ**ì€ ë²ˆì—­ìê°€ ì¢‹ì•„í•˜ëŠ” spidermanì˜ ë³„ëª… friendly neighborhood spider manì„ ì¹œì ˆí•œ ì´ì›ƒ ìŠ¤íŒŒì´ë”ë§¨ê³¼ ê°™ì´ ì˜ˆì˜ê²Œ ë²ˆì—­í•œ ë‹¨ì–´ê°™ì§€ë§Œ `nearest neighbor`ë¼ëŠ” ì•Œê³ ë¦¬ì¦˜ ì´ë¦„ì…ë‹ˆë‹¤.

ì´ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì²« ë²ˆì§¸ ëª©ì ì„ ì£¼ë¡œ ë‹¤ë£¨ì§€ë§Œ, ì„ë² ë”©ì—ì„œ ì‹œê°í™”ë¥¼ í•˜ëŠ” ë°©ë²•ë„ ì‚´í´ë³¼ ê²ƒì…ë‹ˆë‹¤. ì‹ ê²½ë§ ì„ë² ë”©ì˜ ì‹¤ì§ˆì ì¸ ì ìš©ì—ëŠ” ê¸°ê³„ ë²ˆì—­ì„ ìœ„í•œ [ì›Œë“œ ì„ë² ë”©(word embedding)](https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9) ë° ì¹´í…Œê³ ë¦¬ì»¬ ë³€ìˆ˜ë¥¼ ìœ„í•œ [ì—”í‹°í‹° ì„ë² ë”©(entity embedding)](https://arxiv.org/abs/1604.06737) ë“±ì´ ìˆìŠµë‹ˆë‹¤.




### ë°ì´í„° : ìœ„í‚¤í”¼ë””ì•„ì˜ ëª¨ë“  ì±…ë“¤ (Data: All Books on Wikipedia)

ì—¬ëŠ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ í”„ë¡œì íŠ¸ì™€ ë§ˆì°¬ê°€ì§€ë¡œ, ìš°ë¦¬ëŠ” ê³ í’ˆì§ˆì˜ ë°ì´í„° ì…‹ì„ ì¤€ë¹„í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. ì´ [ê¸€](https://towardsdatascience.com/wikipedia-data-science-working-with-the-worlds-largest-encyclopedia-c08efbac5f5c)ì—ì„œ, ìœ„í‚¤í”¼ë””ì•„ì— ìˆëŠ” ëª¨ë“  ìë£Œë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ê³  ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ë³´ì•˜ìŠµë‹ˆë‹¤. ì±…ì— ê´€í•œ ëª¨ë“  í˜ì´ì§€ë¥¼ ê²€ìƒ‰í•´ ì±…ì˜ ì œëª©, ê¸°ë³¸ ì •ë³´, ë‹¤ë¥¸ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€(ìœ„í‚¤ë§í¬)ë¥¼ ê°€ë¦¬í‚¤ëŠ” ë§í¬, ì™¸ë¶€ ì‚¬ì´íŠ¸ ë§í¬ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ì´ ì¤‘ì—ì„œ ì¶”ì²œ ì‹œìŠ¤í…œì„ ë§Œë“¤ê¸° ìœ„í•´ í•„ìš”í•œ ì •ë³´ëŠ” *ì œëª©*ê³¼ *ìœ„í‚¤ë§í¬* ë‘ ê°€ì§€ì…ë‹ˆë‹¤.



```
Book Title: 'The Better Angels of Our Nature'
Wikilinks:  
['Steven Pinker',
  'Nation state',
  'commerce',
  'literacy',
  'Influence of mass media',
  'Rationality',
  "Abraham Lincoln's first inaugural address",
  'nature versus nurture',
  'Leviathan']
```



ì‹ ê²½ë§ì„ ì‚¬ìš©í•  ë•Œë„ ë°ì´í„°ë¥¼ íƒìƒ‰í•˜ê³  ì •ë¦¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì— ì›ì‹œ ë°ì´í„°ë¥¼ ëª‡ ê°€ì§€ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ìˆ˜ì •ì˜ ì˜ˆë¡œ, ê°€ì¥ ë§ì´ ì—°ê²°ëœ í˜ì´ì§€ë¥¼ ì‚´í´ë³¸ ê²ƒì…ë‹ˆë‹¤.



![ê°€ì¥_ë§ì´_ì—°ê²°ëœ_í˜ì´ì§€](130_2.png)  

*figure2 : ìœ„í‚¤í”¼ë””ì•„ì˜ í˜ì´ì§€ëŠ” ìœ„í‚¤í”¼ë””ì•„ì— ìˆëŠ” ì±…ë“¤ë¡œ ê°€ì¥ ìì£¼ ì—°ê²°ë©ë‹ˆë‹¤.*



ìš°ë¦¬ëŠ” figure2ë¥¼ ë³´ê³  ìƒìœ„ 4ê°œ í˜ì´ì§€ëŠ” ì¼ë°˜ì ì´ë©° ì¶”ì²œ ì‹œìŠ¤í…œì„ ë§Œë“œëŠ” ë° ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì±…ì˜ í˜•ì‹ì€ ê·¸ ë‚´ìš©ê³¼ ê´€ë ¨ì´ ì—†ë‹¤ëŠ” ê²ƒì„ ì•Œê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.ğŸ¤¨ í•œ ì±…ì´ `ì¢…ì´ë¡œ ëœ ì±…`ì¸ì§€ `í•˜ë“œì»¤ë²„`ì¸ì§€ì— ëŒ€í•œ ì •ë³´ë¡œ ì‹ ê²½ë§ì„ í†µí•´ ì±…ê³¼ ë‚´ìš©ì´ ìœ ì‚¬í•œ ë‹¤ë¥¸ ì±…ì„ ì•Œì•„ë‚¼ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ, ìš°ë¦¬ëŠ” ì´ ì—°ê²°ê³ ë¦¬ë¥¼ ì œê±°í•  ê²ƒì…ë‹ˆë‹¤.

ìµœì¢… ëª©ì ì— ëŒ€í•´ ìƒê°í•˜ëŠ” ê²ƒì€ ë°ì´í„° ì •ë¦¬ ë‹¨ê³„ì—ì„œ ë„ì›€ì´ ë  ìˆ˜ ìˆê³ , ì´ëŸ¬í•œ ë°©ë²•ë§Œìœ¼ë¡œë„ ì¶”ì²œ ì‹œìŠ¤í…œì„ í¬ê²Œ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ìˆœìˆ˜í•œ í˜¸ê¸°ì‹¬ì—ì„œ, ì €ëŠ” ìœ„í‚¤í”¼ë””ì•„ì— ê´€í•œ ë‹¤ë¥¸ ì±…ë“¤ê³¼ ê°€ì¥ ê´€ë ¨ì´ ë§ì€(ë§í¬ê°€ ë§ì€) ì±…ì„ ì°¾ê³  ì‹¶ì—ˆìŠµë‹ˆë‹¤. figure 3ì€ "ê°€ì¥ ë§ì´ ì—°ê²°ëœ" 10ê¶Œì˜ ìœ„í‚¤í”¼ë””ì•„ ì±…ì…ë‹ˆë‹¤.



![](130_3.png)

*figure3 : ìœ„í‚¤í”¼ë””ì•„ì˜ ë‹¤ë¥¸ ì±…ë“¤ê³¼ ê°€ì¥ ë§ì´ ì—°ê²°ë˜ì–´ ìˆëŠ” ìœ„í‚¤í”¼ë””ì•„ì˜ ì±…ë“¤*



ì´ê²ƒì€ ì°¸ê³ ì„œì ê³¼ ê³ ì „ì„œì ë“¤ ì…ë‹ˆë‹¤.

ë°ì´í„° í´ë¦¬ë‹ í›„, ìš°ë¦¬ëŠ” **41758**ê°œì˜ ìœ ë‹ˆí¬í•œ ìœ„í‚¤ë§í¬ì™€ **37020**ê°œì˜ ìœ ë‹ˆí¬í•œ ì±…ì„ ê°€ì§€ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë“  ì‚¬ëŒë“¤ì„ ìœ„í•œ ì±…ì´ ì´ ì¤‘ì— ìˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤! ğŸ™

ë°ì´í„°ê°€ ê¹¨ë—í•˜ë‹¤ê³  í™•ì‹ ì´ ë“¤ê³ , (ì±… ì œëª©, ìœ„í‚¤ë§í¬) ìŒì´ ì£¼ì–´ì§€ë©´, ìœ„í‚¤ë§í¬(wikilink)ê°€ ì±…ì˜ ê¸°ì‚¬ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.




### ì§€ë„í•™ìŠµí•˜ê¸° (Supervised Learning Task)

**ì˜ë¯¸ ìˆëŠ” ì„ë² ë”©**ì„ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œ, ìš°ë¦¬ì˜ ì‹ ê²½ë§ì´ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ë„ë¡ í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤. í”„ë¡œì íŠ¸ì˜ ê°€ì •(ë¹„ìŠ·í•œ ì±…ì´ ë¹„ìŠ·í•œ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ì™€ ì—°ê²°ëœë‹¤ëŠ”)ì„ í†µí•´ ìš°ë¦¬ëŠ” ë¬¸ì œë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì±… ì œëª©, ìœ„í‚¤ë§í¬) ìŒì´ ì£¼ì–´ì§€ë©´, ìœ„í‚¤ë§í¬ê°€ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

ì‹ ê²½ë§ì— ì±… ë‚´ìš©ì„ ì œê³µí•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹  ì±… ì œëª©, ìœ„í‚¤ë§í¬, ë¼ë²¨ë¡œ êµ¬ì„±ëœ ìˆ˜ì‹­ë§Œ ê°œì˜ êµìœ¡ ì˜ˆì œë¥¼ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤. ì‹ ê²½ë§ì— True ë°ì´í„°ì…‹ê³¼ False ë°ì´í„°ì…‹ì„ ì…ë ¥í•˜ê³ , ë§ˆì§€ë§‰ìœ¼ë¡œ ì„ë² ë”©ì— ëŒ€í•œ ì •ë³´ë¥¼ í•™ìŠµí•˜ì—¬ ìœ„í‚¤ë§í¬ê°€ ì±… í˜ì´ì§€ì— í‘œì‹œë˜ëŠ” ì‹œì ì„ êµ¬ë¶„í•©ë‹ˆë‹¤.

ì´ í”„ë¡œì íŠ¸ì˜ ê°€ì¥ ì¤‘ì—¬í•œ ë¶€ë¶„ì€ ì§€ë„í•™ìŠµì„ í‘œí˜„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì„ë² ë”©ì€ íŠ¹ì • ì‘ì—…ì— ëŒ€í•´ í•™ìŠµë˜ë©° í•´ë‹¹ ë¬¸ì œì™€ë§Œ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ìš°ë¦¬ì˜ ì„ë¬´ê°€ ì œì¸ ì˜¤ìŠ¤í‹´ì´ ì“´ ì±…ë“¤ì„ ì°¾ì•„ë‚´ëŠ” ê²ƒì´ì—ˆë‹¤ë©´, ì´ ì„ë² ë”©ë“¤ì€ ê·¸ ëª©í‘œë¥¼ ë°˜ì˜í•˜ì—¬ ì˜¤ìŠ¤í‹´ì´ ì“´ ì±…ë“¤ì„ ì„ë² ë”© ê³µê°„ì—ì„œ ë” ê°€ê¹ê²Œ í•¨ê»˜ ë†“ì•˜ì„ ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì±… í˜ì´ì§€ì— íŠ¹ì • ìœ„í‚¤ë§í¬ê°€ ìˆëŠ”ì§€ ì•Œì•„ë³´ê¸° ìœ„í•œ í•™ìŠµì„ í†µí•´, ë„¤íŠ¸ì›Œí¬ëŠ” ì½˜í…ì¸  ì¸¡ë©´ì—ì„œ ìœ ì‚¬í•œ ì±…ì„ ì„œë¡œ ê°€ê¹Œì´ ë‘ëŠ” ê²ƒì„ ë°°ìš°ê¸°ë¥¼ í¬ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ìš°ë¦¬ê°€ í•´ì•¼í•  ì¼ë“¤ì´ ì •ë¦¬ê°€ ë˜ì—ˆë‹¤ë©´, ì´ì œëŠ” ê·¸ê²ƒì„ ì½”ë“œë¡œ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤. ì‹ ê²½ë§ì—ëŠ” ì •ìˆ˜ë§Œ ì…ë ¥í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ê° ê³ ìœ  ì±…ìì—ì„œ ì •ìˆ˜ë¡œì˜ ë§¤í•‘ì„ ë§Œë“­ë‹ˆë‹¤.



```python
# ì±… ì´ë¦„ê³¼ ì±…ì˜ ê³ ìœ  ì¸ë±ìŠ¤ index ë§µí•‘
book_index = {book[0]: idx for idx, book in enumerate(books)}

book_index['Anna Karenina']
22494
```



ë§í¬ì—ë„ ë™ì¼í•œ ì‘ì—…ì„ í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ í•™ìŠµ ë°ì´í„° ì…‹ì„ ë§Œë“¤ê¸° ìœ„í•´ ë°ì´í„°ì— ìˆëŠ” ëª¨ë“ (ì±…, ìœ„í‚¤ë§í¬) ìŒì„ ë‚˜ì—´í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œëŠ” ê° ì±…ì„ ë°˜ë³µí•˜ê³  í˜ì´ì§€ì— ìˆëŠ” ê° ìœ„í‚¤ë§í¬ì— ëŒ€í•œ ì˜ˆë¥¼ ê¸°ë¡í•´ì•¼ í•©ë‹ˆë‹¤.



```python
pairs = []

# ê°ê° ì±…ì´ ë‚˜ì˜¤ë„ë¡ ë°˜ë³µ
for book in books:

    title = book[0]
    book_links = book[2]
    # ì±…ì— ê´€í•œ ê¸€ì— ìˆëŠ” wikilinks ë“¤ì„ ë°˜ë³µ
    for link in book_links:
        # ì±…ì˜ ì¸ë±ìŠ¤ì™€ ë§í¬ í˜ì–´ ì €ì¥
        pairs.extend((book_index[title],                
                      link_index[link]))
```



ì´ê²ƒì€ ìš°ë¦¬ê°€ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê¸° ìœ„í•´ í‘œë³¸ìœ¼ë¡œ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” ì´ **772798ê°œ**ì˜ `True` ì˜ˆë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. `False` ì˜ˆì œë¥¼ ìƒì„±í•˜ë ¤ë©´(ë‚˜ì¤‘ì— ìˆ˜í–‰ë¨) ë§í¬ ì¸ë±ìŠ¤ì™€ ì±… ì¸ë±ìŠ¤ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•˜ê³ , ê·¸ ë‘ ê°œê°€ `True`ê°€ ì•„ë‹Œì§€ í™•ì¸í•œ ë‹¤ìŒ `False` ì˜ˆì œë¡œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.

> `True`ì¸ ì˜ˆë¼ëŠ” ê²ƒì€ ë§í¬(ì •í™•íˆëŠ” ë§í¬ ì¸ë±ìŠ¤)ê°€ ì±…(ì •í™•íˆëŠ” ì±… ì¸ë±ìŠ¤)ì´ ê°€ì§€ê³  ìˆëŠ” ì¸ë±ìŠ¤ë¼ëŠ” ê²ƒì´ê³ , `False`ì¸ ì˜ˆëŠ” ë§í¬ê°€ ì±…ì´ ê°€ì§€ê³  ìˆëŠ” ë§í¬ê°€ ì•„ë‹ ë•Œì˜ ê²½ìš°ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ë§í¬ì™€ ì±…ì´ ì˜¬ë°”ë¥¸ í•œ ìŒì¼ ë•ŒëŠ” `True`, ì•„ë‹ ë•ŒëŠ” `False`ë¼ê³  í•  ìˆ˜ ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.

##### í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ ì°¸ê³  ì‚¬í•­ (Note about Training / Testing Sets)

ë³„ë„ì˜ ê²€ì¦(validation set) ë° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì¸ ì§€ë„í•™ìŠµ ì‘ì—…ì˜ í•„ìˆ˜ ì‚¬í•­ì´ì§€ë§Œ, ì´ ê²½ìš° ê°€ì¥ ì •í™•í•œ ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì„ë² ë”© ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” ê²ƒì´ ì£¼ëœ ëª©í‘œì…ë‹ˆë‹¤. ì˜ˆì¸¡ ì‘ì—…ì€ ì„ë² ë”©ì„ ìœ„í•´ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµí•˜ëŠ” ìˆ˜ë‹¨ì¼ ë¿ì…ë‹ˆë‹¤. êµìœ¡ì´ ëë‚˜ë©´ ìƒˆ ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•˜ê±°ë‚˜ ê²€ì¦ ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë²„í•(overfitting)ì„ ë°©ì§€í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœìƒì˜ ì„ë² ë”© ê°’ì„ í™•ë³´í•˜ê¸° ìœ„í•´ ëª¨ë“  ë°ì´í„°ë¥¼ í•™ìŠµì— ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ğŸ˜¬




### ì„ë² ë”© ëª¨ë¸ (Embedding Model)

ì‹ ê²½ë§ì´ ê¸°ìˆ ì ìœ¼ë¡œ ë³µì¡í•œ ê²ƒì²˜ëŸ¼ ë“¤ë¦¬ì§€ë§Œ, [ì¼€ë¼ìŠ¤ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬](https://keras.io)ë¡œ ë¹„êµì  ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ‘ğŸ‘ í…ì„œí”Œë¡œìš°(TensorFlow)ëŠ” ë” ë§ì€ ë” ë§ì€ ê²ƒì„ ì œì–´í•  ìˆ˜ ìˆì§€ë§Œ, êµ¬í˜„ì˜ í¸ë¦¬í•¨ì— ìˆì–´ ì¼€ë¼ìŠ¤ë¥¼ ëŠ¥ê°€í•  ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤.

ì„ë² ë”© ëª¨ë¸ì€ 5ê°œì˜ ë ˆì´ì–´ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

1. Input: ì±… ë° ë§í¬ì— ëŒ€í•œ ë³‘ë ¬ ì…ë ¥.
2. Embedding: ì±… ë° ë§í¬ë¥¼ ìœ„í•œ ë³‘ë ¬ ê¸¸ì´ 50ê°œì˜ ì„ë² ë”©.
3. Dot: ë‚´ì (dot product)ì„ ê³„ì‚°í•˜ì—¬ ì„ë² ë”© í•©ì¹˜ê¸°.
4. Reshape: ì„ë² ë”© shapeë¥¼ ë‹¨ì¼ ìˆ«ìë¡œ í˜•ì„±.
5. Dense: ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™”ë¥¼ ì´ìš©í•œ ì¶œë ¥.

[Embedding neural network](https://keras.io/layers/embeddings/)ì—ì„œ ì„ë² ë”©ì€ ëª©í‘œì˜ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ í›ˆë ¨ ì¤‘ì— ì¡°ì •ë˜ëŠ” ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜(weight)ì…ë‹ˆë‹¤. ì‹ ê²½ë§ì€ ì±…ê³¼ ë§í¬ë¥¼ ì •ìˆ˜ë¡œ ì‚¬ìš©í•˜ì—¬ 0ê³¼ 1 ì‚¬ì´ì˜ ì˜ˆì¸¡ì„ ì¶œë ¥í•˜ë©°, ì´ëŠ” ì‹¤ì œ ê°’ê³¼ ë¹„êµë©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ [`Adam Optimizer`(Stochastic Gradient Descent Descent Descentì˜ ë³€í˜•)](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)ë¡œ ì»´íŒŒì¼ë˜ë©°, ì´ ê³¼ì •ì—ì„œ ì´ ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì— ëŒ€í•œ `binary_crossentropy`ê°’ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.



ì•„ë˜ëŠ” ëª¨ë¸ ì½”ë“œì…ë‹ˆë‹¤:

```python
from keras.layers import Input, Embedding, Dot, Reshape, Dense
from keras.models import Model

def book_embedding_model(embedding_size = 50, classification = False):
    """Model to embed books and wikilinks using the Keras functional API.
       Trained to discern if a link is present in on a book's page"""

    # 1ì°¨ì›ì˜ ì…ë ¥
    book = Input(name = 'book', shape = [1])
    link = Input(name = 'link', shape = [1])

    # ì±… ì„ë² ë”© (shape will be (None, 1, 50))
    book_embedding = Embedding(name = 'book_embedding',
                               input_dim = len(book_index),
                               output_dim = embedding_size)(book)

    # ë§í¬ ì„ë² ë”© (shape will be (None, 1, 50))
    link_embedding = Embedding(name = 'link_embedding',
                               input_dim = len(link_index),
                               output_dim = embedding_size)(link)

    # ë‚´ì ìœ¼ë¡œ ì±… ì„ë² ë”©ê³¼ ë§í¬ ì„ë² ë”©ì„ í•œ ê°œì˜ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í˜•
    # (shape will be (None, 1, 1))
    merged = Dot(name = 'dot_product', normalize = True,
                 axes = 2)([book_embedding, link_embedding])

    # ë‹¨ì¼ ìˆ«ìë¡œ shape ë³€í˜• (shape will be (None, 1))
    merged = Reshape(target_shape = [1])(merged)

    # ë¶„ë¥˜ë¥¼ ìœ„í•œ ê²°ê³¼ê°’ ì¶œë ¥
    out = Dense(1, activation = 'sigmoid')(merged)
    model = Model(inputs = [book, link], outputs = out)

    # ì›í•˜ëŠ” optimizer ì™€ loss í•¨ìˆ˜ë¡œ ëª¨ë¸ í•™ìŠµ ì‹œì‘
    model.compile(optimizer = 'Adam', loss = 'binary_crossentropy',
                  metrics = ['accuracy'])

    return model
```



ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë§ì€ ì„ë² ë”© ëª¨ë¸ì— ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ì ì€ ì„ë² ë”©ì´ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ì´ë©° ë˜í•œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ìµœì¢… ê²°ê³¼ë¼ëŠ” ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê·¸ ëª¨ë¸ì´ ì •í™•í•œì§€ ê·¸ë‹¤ì§€ ì‹ ê²½ì“°ì§€ ì•Šì„ ê²ƒ ì…ë‹ˆë‹¤, ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²ƒì€ ì ì ˆí•œ ì„ë² ë”© ë²¡í„°ì…ë‹ˆë‹¤.

ìš°ë¦¬ëŠ” ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì •í™•í•œ ì˜ˆì¸¡ì„ ìœ„í•œ ìˆ˜ë‹¨ìœ¼ë¡œì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì— ìµìˆ™í•´ì ¸ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì„ë² ë”© ëª¨ë¸ì—ì„œëŠ” ê°€ì¤‘ì¹˜ê°€ ëª©í‘œì´ê³  ì˜ˆì¸¡ì€ ë‹¨ì§€ ì„ë² ë”©ì„ í•™ìŠµí•˜ê¸° ìœ„í•œ ìˆ˜ë‹¨ì¼ ë¿ì…ë‹ˆë‹¤.



ì•½ 400 ë§Œ ê°œì˜ weightë¥¼ model summaryë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
book (InputLayer)               (None, 1)            0                                            
__________________________________________________________________________________________________
link (InputLayer)               (None, 1)            0                                            
__________________________________________________________________________________________________
book_embedding (Embedding)      (None, 1, 50)        1851000     book[0][0]                       
__________________________________________________________________________________________________
link_embedding (Embedding)      (None, 1, 50)        2087900     link[0][0]                       
__________________________________________________________________________________________________
dot_product (Dot)               (None, 1, 1)         0           book_embedding[0][0]             
                                                                 link_embedding[0][0]             
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 1)            0           dot_product[0][0]                
==================================================================================================
Total params: 3,938,900
Trainable params: 3,938,900
Non-trainable params: 0
```



ì´ ì ‘ê·¼ë²•ìœ¼ë¡œ ìš°ë¦¬ëŠ” ì±…ë¿ë§Œ ì•„ë‹ˆë¼ ì±…ìœ¼ë¡œ ì—°ê²°ëœ ëª¨ë“  ìœ„í‚¤í”¼ë””ì•„ì˜ í˜ì´ì§€ë¥¼ ë¹„êµí•  ìˆ˜ ìˆëŠ” ë§í¬ë“¤ì— ëŒ€í•œ ì„ë² ë”©ë„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.




### í•™ìŠµ ìƒ˜í”Œ ë§Œë“¤ê¸° (Generating Training Samples)

ì‹ ê²½ë§ì€ [batch learner](https://en.wikipedia.org/wiki/Online_machine_learning#Batch_learning)ì…ë‹ˆë‹¤. ì™œëƒí•˜ë©´ í•œ ë²ˆì— í•˜ë‚˜ì˜ ì‘ì€ í‘œë³¸ ì§‘í•©(ê´€ì°°)ì„ í†µí•´ epochë¼ê³  ë¶ˆë¦¬ëŠ” ë§ì€ ë¼ìš´ë“œì—ì„œ í›ˆë ¨ì„ ë°›ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì‹ ê²½ë§ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ì¼ë°˜ì ì¸ ë°©ë²•ì€ generatorë¥¼ ì´ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì „ì²´ ê²°ê³¼ê°€ ë©”ëª¨ë¦¬ì— ì €ì¥ë˜ì§€ ì•Šë„ë¡, `yields`(not `returns`)í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ í•˜ë ¤ê³  í•˜ëŠ” ì£¼ì œëŠ” ì•„ë‹ˆì§€ë§Œ generatorì˜ ì´ì ì€ í° ì‚¬ì´ì¦ˆì˜ í•™ìŠµ ë°ì´í„° ì…‹ì„ ëª¨ë‘ ë©”ëª¨ë¦¬ì— ë¡œë“œí•  í•„ìš”ê°€ ì—†ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

> ì—¬ê¸°ì„œ ë§í•˜ëŠ” generatorëŠ” GANs ì˜ generatorê°€ ì•„ë‹ˆë¼ pythonì—ì„œ ì œê³µí•˜ëŠ” generatorë¥¼ ë§í•©ë‹ˆë‹¤.

ìš°ë¦¬ì˜ GeneratorëŠ” `í˜ì–´(pairs)`ë¡œ í•™ìŠµë˜ì—ˆê³ , í•œ ë°°ì¹˜ ë‹¹ ê¸ì • ìƒ˜í”Œ  ìˆ˜(`n_positive`) ë° í•œ ë°°ì¹˜ ë‹¹ ë¶€ì • ìƒ˜í”Œ:ê¸ì • ìƒ˜í”Œ ë¹„ìœ¨(`negative_ratio`)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. generatorëŠ” í˜¸ì¶œí•  ë•Œë§ˆë‹¤ ê¸ì • ìƒ˜í”Œê³¼ ë¶€ì • ìƒ˜í”Œì˜ ìƒˆ ë°°ì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ê¸ì •ì ì¸ ì˜ˆë¥¼ ì–»ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë¬´ì‘ìœ„ë¡œ `Ture` ìŒ(pair)ì„ í‘œë³¸ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤. `False`ì¸ ì˜ˆì œì˜ ê²½ìš°, ë¬´ì‘ìœ„ë¡œ ì±…ê³¼ ë§í¬ë¥¼ ìƒ˜í”Œë§í•˜ì—¬ ì´ ìŒì´ ì‹¤ì œ ìŒì— ìˆì§€ ì•Šì€ì§€ í™•ì¸í•œ ë‹¤ìŒ ë°°ì¹˜ì— ì¶”ê°€í•©ë‹ˆë‹¤.



ì•„ë˜ ì½”ë“œëŠ” generator ì „ì²´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

```python
import numpy as np
import random
random.seed(100)

def generate_batch(pairs, n_positive = 50, negative_ratio = 1.0):
    """Generate batches of samples for training.
       Random select positive samples
       from pairs and randomly select negatives."""

    # batchë¥¼ ì €ì¥í•  numpy ë°°ì—´ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
    batch_size = n_positive * (1 + negative_ratio)
    batch = np.zeros((batch_size, 3))

    while True:
        # ëœë¤ìœ¼ë¡œ Trueì¸ ìƒ˜í”Œì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
        for idx, (book_id, link_id) in enumerate(random.sample(pairs, n_positive)):
            batch[idx, :] = (book_id, link_id, 1)
        idx += 1

        # ë°°ì¹˜ ì‚¬ì´ì¦ˆê°€ ë‹¤ ì°° ë•Œê¹Œì§€ Falseì¸ ìƒ˜í”Œì„ ì¶”ê°€í•©ë‹ˆë‹¤.
        while idx < batch_size:

            # Random selection
            random_book = random.randrange(len(books))
            random_link = random.randrange(len(links))

            # Tureì¸ ìƒ˜í”Œì´ ì•„ë‹ˆë¼ëŠ” ê²ƒ(Falseì¸ ìƒ˜í”Œì´ë¼ëŠ” ê²ƒ)ì„ ì²´í¬í•©ë‹ˆë‹¤.
            if (random_book, random_link) not in pairs_set:

                # Falseì¸ ìƒ˜í”Œì„ ë°°ì¹˜ì— ì¶”ê°€í•©ë‹ˆë‹¤.
                batch[idx, :] = (random_book, random_link, neg_label)
                idx += 1

        # ë°°ì¹˜ì— ì €ì¥ëœ ë°ì´í„°ë“¤ì˜ ìˆœì„œë¥¼ ì„ìŠµë‹ˆë‹¤.
        np.random.shuffle(batch)
        yield {'book': batch[:, 0], 'link': batch[:, 1]}, batch[:, 2]
```



ìš°ë¦¬ê°€ generatorë¡œ `next`ë¥¼ ë¶€ë¥¼ ë•Œ ë§ˆë‹¤, ìƒˆ í•™ìŠµ ë°ì´í„° ë°°ì¹˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.




### ëª¨ë¸ í•™ìŠµí•˜ê¸° Training Model

ì„ íƒí•  ìˆ˜ ìˆëŠ” í•™ìŠµ íŒŒë¼ë¯¸í„°ê°€ ëª‡ ê°€ì§€ ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” ê° ë°°ì¹˜ì— í¬í•¨ëœ ê¸ì • ë°ì´í„° ìˆ˜ì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ [ì‘ì€ ë°°ì¹˜ í¬ê¸°ë¡œ ì‹œì‘í•˜ì—¬ ì„±ëŠ¥ì´ ì €í•˜ë  ë•Œê¹Œì§€ ëŠ˜ë¦½ë‹ˆë‹¤.](https://arxiv.org/abs/1609.04836) ë˜í•œ, ìš°ë¦¬ëŠ” ê°ê°ì˜ ê¸ì • ë°ì´í„°ì— ëŒ€í•´ í›ˆë ¨ëœ ë¶€ì • ë°ì´í„° ìˆ˜ë¥¼ ì„ íƒí•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ê²ƒì´ ê°€ì¥ ì˜ ì‘ë™í•˜ëŠ”ì§€ ì•Œì•„ë³´ê¸° ìœ„í•´ ëª‡ ê°€ì§€ ì˜µì…˜ìœ¼ë¡œ ì‹¤í—˜í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” [early stopping](https://keras.io/callbacks/#earlystopping)ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ validation ì…‹ì„ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—, training lossì´ ê°ì†Œí•˜ì§€ ì•ŠëŠ” ì—¬ëŸ¬ epochs ì„ ì„ íƒí•©ë‹ˆë‹¤.



```python
n_positive = 1024

gen = generate_batch(pairs, n_positive, negative_ratio = 2)

# Train
h = model.fit_generator(gen, epochs = 15,
                        steps_per_epoch = len(pairs) // n_positive)
```



(í•™ìŠµ íŒŒë¼ë¯¸í„°ê°€ ë§‰ì—°í•˜ê²Œ ëŠê»´ì§„ë‹¤ë©´, [Deep Learning](https://www.deeplearningbook.org)ì— ì„¤ëª…ëœ ëª¨ë²” ì‚¬ë¡€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ë³´ì„¸ìš”. ëŒ€ë¶€ë¶„ì˜ ê¸°ê³„í•™ìŠµê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì‹ ê²½ë§ í•™ìŠµë„ ëŒ€ë¶€ë¶„ ê²½í—˜ì—ì„œ ë‚˜ì˜¨ ê²°ê³¼ì…ë‹ˆë‹¤.)



ì¼ë‹¨ ë„¤íŠ¸ì›Œí¬ê°€ í›ˆë ¨ì„ ë§ˆì¹˜ë©´, ìš°ë¦¬ëŠ” ì„ë² ë”©ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# ì„ë² ë”© ë²¡í„° ì¶”ì¶œí•˜ê¸°
book_layer = model.get_layer('book_embedding')
book_weights = book_layer.get_weights()[0]
```




### ì„ë² ë”© ì ìš©í•˜ê¸°: ì¶”ì²œ í•˜ê¸° (Applying Embeddings: Making Recommendations)

ì„ë² ë”© ìì²´ëŠ” ê½¤ í¥ë¯¸ë¡­ì§€ ì•ŠìŠµë‹ˆë‹¤. ê° ì±…ê³¼ ë§í¬ë§ˆë‹¤ 50ê°œì˜ ìˆ«ì ë²¡í„°ì— ë¶ˆê³¼í•©ë‹ˆë‹¤.



![ì„ë² ë”©ë²¡í„°](130_4.png)

*figure4 : What War and Peace Looks Like ë¼ëŠ” ì´ë¦„ì˜ ì±…ì„ ì„ë² ë”© ë²¡í„°ë¡œ í‘œí˜„í•œ ê²ƒ*



í•˜ì§€ë§Œ, ìš°ë¦¬ëŠ” ì´ ë²¡í„°ë¥¼ ë‘ ê°€ì§€ ë‹¤ë¥¸ ëª©ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê³ , ê·¸ ì¤‘ ì²« ë²ˆì§¸ëŠ” ìš°ë¦¬ì˜ ì±… ì¶”ì²œ ì‹œìŠ¤í…œì„ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤. ì„ë² ë”© ê³µê°„ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì±…ì„ ì°¾ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ê·¸ ì±…ì˜ ë²¡í„°ì™€ ë‹¤ë¥¸ ëª¨ë“  ì±…ì˜ ë²¡í„°ì™€ í•¨ê»˜ ë‚´ì ì„ í•©ë‹ˆë‹¤. ì„ë² ë”©ì´ ì •ê·œí™”ëœ ê²½ìš° ë²¡í„° ê°„ì˜ ë‚´ì ì€ ê°€ì¥ ìœ ì‚¬í•˜ì§€ ì•Šì€ -1 ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ +1 ê¹Œì§€ì˜ [cosine similarity](http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.



ë ˆì˜¤ í†¨ìŠ¤í† ì´ì˜ War and Peaceì™€ ë¹„ìŠ·í•œ ì±… ì°¾ê¸° ê²°ê³¼:

```
Books closest to War and Peace.

Book: Anna Karenina               Similarity: 0.92
Book: The Master and Margarita    Similarity: 0.92
Book: Demons (Dostoevsky novel)   Similarity: 0.91
Book: The Idiot                   Similarity: 0.9
Book: Crime and Punishment        Similarity: 0.9
```



ì¶”ì²œë“¤ì´ ê½¤ ë§ì•„ ë–¨ì–´ì§€ì§€ ì•Šë‚˜ìš”?!ğŸ¤© ì´ë“¤ì€ ëª¨ë‘ ëŸ¬ì‹œì•„ ê³ ì „ ì†Œì„¤ì…ë‹ˆë‹¤. ë¬¼ë¡  ìš°ë¦¬ëŠ” ì´ì™€ ê°™ì€ ì¶”ì²œì„ ìœ„í•´ [GoodReads](https://www.goodreads.com/book/show/656.War_and_Peace?ac=1&from_search=true)ë¡œ ê°ˆ ìˆ˜ ìˆì—ˆê² ì§€ë§Œ, ìš°ë¦¬ ìŠ¤ìŠ¤ë¡œ ì‹œìŠ¤í…œì„ ë§Œë“œëŠ” ê²ƒì€ ì–´ë–¨ê¹Œìš”? ì €ëŠ” ì—¬ëŸ¬ë¶„ì´ notebookìœ¼ë¡œ ì§ì ‘ ì„ë² ë”©ì„ í•´ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.



```
Books closest to The Fellowship of the Ring.
Book: The Return of the King       Similarity: 0.96
Book: The Silmarillion             Similarity: 0.93
Book: Beren and LÃºthien            Similarity: 0.91
Book: The Two Towers               Similarity: 0.91
```



ì±…ì„ ì„ë² ë”©í•˜ëŠ” ê²ƒ ì™¸ì—ë„, ì£¼ì–´ì§„ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ì—ì„œ ì£¼ì–´ì§„ ê°€ì¥ ìœ ì‚¬í•œ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ë§í¬ë„ í¬í•¨í–ˆìŠµë‹ˆë‹¤.

```
Pages closest to steven pinker.

Page: the blank slate           Similarity: 0.83
Page: evolutionary psychology   Similarity: 0.83
Page: reductionism              Similarity: 0.81
Page: how the mind works        Similarity: 0.79
```




í˜„ì¬, ì €ëŠ” Bully for Brontosausë¼ê³  ë¶ˆë¦¬ëŠ” Stephen Jay Gouldì˜ í™˜ìƒì ì¸ ìˆ˜í•„ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì—ëŠ” ë¬´ì—‡ì„ ì½ì–´ì•¼ í•˜ëŠ”ì§€ ìƒê°í•œë‹¤ë©´ ì–´ë–»ê²Œ ë ê¹Œìš”?

![ì¶”ì²œ](130_5.png)

*figure5 : ë‚´ê°€ ë‹¤ìŒì— ì½ì–´ì•¼ í•  ì±…ì— ëŒ€í•œ ì¶”ì²œ*




### ì„ë² ë”© ì‹œê°í™” (Visualizations of Embeddings)

ì„ë² ë”©ì˜ ê°€ì¥ í¥ë¯¸ë¡œìš´ ì¸¡ë©´ ì¤‘ í•˜ë‚˜ëŠ” ì„œë¡œ ìƒëŒ€ì ìœ¼ë¡œ *ì†Œì„¤* ë˜ëŠ” *ë…¼í”½ì…˜*ê³¼ ê°™ì€ ê°œë…ì„ ì‹œê°í™”í•˜ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œëŠ” ì°¨ì›ì„ 2ì°¨ì› ë˜ëŠ” 3ì°¨ì›ìœ¼ë¡œ ê°ì†Œì‹œí‚¤ëŠ” dimension reduction ê¸°ìˆ ì´ í•„ìš”í•©ë‹ˆë‹¤. ê°€ì¥ ì¸ê¸° ìˆëŠ” ì°¨ì› ê°ì†Œ ê¸°ìˆ ì€ ë‹¤ìŒì˜ ë°©ë²•ì…ë‹ˆë‹¤: [t-Distributed Stochastic Neighbor Embedding(TSNE)](https://distill.pub/2016/misread-tsne/).

ìœ„í‚¤í”¼ë””ì•„ì— ìˆëŠ” ëª¨ë“  ì±…ì˜ 37,000ì°¨ì› ê³µê°„ì„ ì‹œì‘ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ 50ê°œì˜ ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•œ ë‹¤ìŒ TSNEë¡œ 2ì°¨ì›ì— ë§¤í•‘í•©ë‹ˆë‹¤. ì´ê²ƒì€ ë‹¤ìŒ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.



![ì„ë² ë”©ì‹œê°í™”](130_6.png)

*figure6 : ìœ„í‚¤í”¼ë””ì•„ì— ìˆëŠ” ëª¨ë“  ì±…ë“¤ì— ëŒ€í•œ ì„ë² ë”©ì˜ ê²°ê³¼*



ì´ ì´ë¯¸ì§€ ìì²´ì— ìƒ‰ì´ ìˆëŠ” ê²ƒì€ ì•„ë‹ˆì§€ë§Œ, ì¼ë‹¨ ì±… íŠ¹ì„±ì— ë”°ë¼ ìƒ‰ì¹ í•˜ê¸° ì‹œì‘í•˜ë©´, ìš°ë¦¬ëŠ” í´ëŸ¬ìŠ¤í„°ê°€ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![ì„ë² ë”©ì‹œê°í™”2](130_7.png)

*figure7 : ìƒ‰ìœ¼ë¡œ êµ¬ë¶„ë˜ëŠ” ì„ë² ë”© ë²¡í„° ì‹œê°í™”*

ë…¼í”½ì…˜ê³¼ ê³µìƒê³¼í•™ ì†Œì„¤ì— ëšœë ·í•œ ë¶€ë¶„ì´ ìˆëŠ” ëª‡ ê°œì˜ ë¶„ëª…í•œ í´ëŸ¬ìŠ¤í„°ê°€ ìˆìŠµë‹ˆë‹¤. ì†Œì„¤ ë‚´ìš©ì˜ ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•  ë•Œ, ì†Œì„¤ë“¤ì€ ì–´ë””ì—ë‚˜ ìˆëŠ” ê²ƒì²˜ëŸ¼ ë³´ì…ë‹ˆë‹¤.



ë‚˜ë¼ì— ë”°ë¼ ì„ë² ë”©ì„ ì‹œê°í™” í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![ë‚˜ë¼ë³„ì„ë² ë”©ì‹œê°í™”](130_8.png)

*figure8 : ë‚˜ë¼ë³„ ì„ë² ë”© ë²¡í„° ì‹œê°í™”*

ë‚˜ë¼ë³„ êµ¬ë¶„ì´ ì–¼ë§ˆë‚˜ íŠ¹ì´í•œì§€ì— ëŒ€í•´ ì¡°ê¸ˆ ë†€ëìŠµë‹ˆë‹¤! ğŸ˜® ëª…ë°±íˆ ì˜¤ìŠ¤íŠ¸ë ˆì¼ë¦¬ì•„ì˜ ì±…ë“¤ì€ ë§¤ìš° ë…íŠ¹í•˜ê²Œ ë³´ì…ë‹ˆë‹¤.



ë˜í•œ Wikipedia ì§€ë„ì—ì„œ íŠ¹ì • ì±…ì„ ê°•ì¡° í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![ì±…ê°•ì¡°ì‹œê°í™”](130_9.png)

*figure9 : íŠ¹ì • ì„ë² ë”© ë²¡í„°ì˜ ê°•ì¡°*



ì—„ì²­ë‚˜ê²Œ ë§ì€ ì‹œê°í™”ê°€ notebookì— ìˆê³ , ìŠ¤ìŠ¤ë¡œë„ ë§Œë“¤ì–´ ë³¼ ìˆ˜ ìˆì„ ê²ë‹ˆë‹¤. ê°€ì¥ ë§ì´ ì—°ê²°ëœ 10ê¶Œì˜ ì±…ì„ í•œ ê¶Œ ë” ë³´ì—¬ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

![ì±…ê°•ì¡°ì‹œê°í™”](130_10.png)

*figure10 : ì±…ê³¼ ì¥ë¥´ì— ê°€ì¥ ë§ì´ ì—°ê²°ëœ 10ê°œì˜ ì±…ë“¤ì´ ë³´ì…ë‹ˆë‹¤*



TSNEì— ëŒ€í•´ ì£¼ëª©í•´ì•¼ í•  í•œ ê°€ì§€ëŠ” ì›ë˜ ê³µê°„ì—ì„œ ë²¡í„° ê°„ì˜ ê±°ë¦¬ë¥¼ ìœ ì§€í•˜ë ¤ê³  í•˜ì§€ë§Œ ì°¨ìˆ˜ê°€ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸ì— ì›ë˜ ê³µê°„ì„ ì™œê³¡í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ 50ì°¨ì› ë§¤ë¦½ ê³µê°„ì—ì„œ ì„œë¡œ ê°€ê¹Œìš´ ì±…ë“¤ì€ 2ì°¨ì› TSNE ë§¤ë¦½ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.




## Interactive ì‹œê°í™” (Interactive Visualizations)

ì´ëŸ¬í•œ ì‹œê°í™”ëŠ” ë§¤ìš° í¥ë¯¸ë¡­ì§€ë§Œ, ì‹ ê²½ë§ ì„ë² ë”©ì„ ì‹œê°í™”í•˜ë„ë¡ íŠ¹ë³„íˆ ì„¤ê³„ëœ í…ì„œí”Œë¡œìš°ì˜ projector ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë†€ë¼ìš´ ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”ë¥¼ í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë„êµ¬ì˜ ì‚¬ìš© ë°©ë²•ì— ëŒ€í•œ ê¸€ì„ ì“¸ ê³„íšì´ì§€ë§Œ, ëª‡ ê°€ì§€ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.



![Interactive visualization](130_11.gif)

*figure11 : tensorflowì˜ projectorë¥¼ ì‚¬ìš©í•œ Interactive visualization*



ì±…ì— ëŒ€í•œ Interactive ì‹œê°í™”ë¥¼ ë³´ê³ ì‹¶ë‹¤ë©´ [ì—¬ê¸°](https://projector.tensorflow.org/?config=https://raw.githubusercontent.com/WillKoehrsen/wikipedia-data-science/master/embeddings/metadata/metadata_sample.json)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.




### í•´ë³¼ ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ í”„ë¡œì íŠ¸ë“¤ (Potential Other Projects)

ë°ì´í„° ê³¼í•™ í”„ë¡œì íŠ¸ëŠ” ëŒ€ê°œ ì™„ì „íˆ ì €ì ˆë¡œ ë°œëª…ë˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ì œê°€ ì—°êµ¬í•˜ëŠ” ë§ì€ í”„ë¡œì íŠ¸ëŠ” ì œê°€ ë…íŠ¹í•œ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì ì‘í•˜ê³ , ê°œì„ í•˜ê³ , êµ¬ì¶•í•˜ëŠ” ë‹¤ë¥¸ ë°ì´í„° ê³¼í•™ìë“¤ì˜ ì•„ì´ë””ì–´ë“¤ì…ë‹ˆë‹¤. (ì´ í”„ë¡œì íŠ¸ëŠ” [Deep Learning Cookbook](https://github.com/DOsinga/deep_learning_cookbook)ì˜ ì˜í™” ì¶”ì²œì„ ìœ„í•œ ìœ ì‚¬í•œ í”„ë¡œì íŠ¸ì—ì„œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.)



ì´ëŸ¬í•œ íƒœë„ë¥¼ ì—¼ë‘ì— ë‘ê³  ì´ ì‘ì—…ì„ êµ¬ì¶•í•˜ëŠ” ëª‡ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.

1. ìœ„í‚¤ë§í¬ ëŒ€ì‹  ì™¸ë¶€ ë§í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ì„ ë§Œë“­ë‹ˆë‹¤. ì´ê²ƒì€ ìœ„í‚¤í”¼ë””ì•„ì˜ ì™¸ë¶€ì— ìˆëŠ” ì›¹í˜ì´ì§€ì— ëŒ€í•œ ê²ƒì´ë©° ë‹¤ë¥¸ ì„ë² ë”© ì„ë² ë”©ì„ ë§Œë“¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

2. ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ì§€ë„ í•™ìŠµ ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬ ì¥ë¥´, ì‘ê°€ ë° êµ­ê°€ê°€ í¬í•¨ëœ ì±…ì˜ íŠ¹ì„±ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

3. ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ì£¼ì œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ê³  ìì‹ ë§Œì˜ ì¶”ì²œ ì‹œìŠ¤í…œì„ ë§Œë“œì„¸ìš”. ì‚¬ëŒ, ëœë“œë§ˆí¬ ë˜ëŠ” ì—­ì‚¬ì  ì‚¬ê±´ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ [notebook](https://github.com/WillKoehrsen/wikipedia-data-science/blob/master/notebooks/Downloading%20and%20Parsing%20Wikipedia%20Articles.ipynb)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì–»ì„ ìˆ˜ ìˆê³ , ì´ [notebook](https://github.com/WillKoehrsen/wikipedia-data-science/blob/master/notebooks/Book%20Recommendation%20System.ipynb)ìœ¼ë¡œ ì„ë² ë”© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.



ì´ê²ƒì€ ê²°ì½” ìˆ™ì œê°€ ì•„ë‹ˆë¼, ë‹¹ì‹ ì´ ì½ì€ ê²ƒì„ ì‹¤í–‰ì— ì˜®ê¸°ê³  ì‹¶ì„ë•Œì˜ ì•„ì´ë””ì–´ ì¼ë¿ì…ë‹ˆë‹¤. ë§Œì•½ ë‹¹ì‹ ì´ ì–´ë–¤ í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ê¸°ë¡œ ê²°ì •í•˜ë©´, í•´ë‹¹ í”„ë¡œì íŠ¸ì— ê´€ë ¨ëœ ì´ì•¼ê¸°ë¥¼ ë“£ê³ ì‹¶ì€ ê²ƒì²˜ëŸ¼! ğŸ¤—




### ê²°ê³¼ (Conclusions)

ì‹ ê²½ë§ ì„ë² ë”©ì€ ì´ì‚°í˜• categorical ë³€ìˆ˜ë¥¼ ì—°ì† ë²¡í„°ë¡œ ë‚˜íƒ€ë‚´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. í•™ìŠµëœ ì €ì°¨ì› í‘œí˜„ì€ ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì— ì…ë ¥ë˜ëŠ” ê²ƒê³¼ ê°™ì€ ìœ ì‚¬í•œ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ê±°ë‚˜ ì»¨ì…‰ì„ ì‹œê°í™”í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ì—ì„œ, ìš°ë¦¬ëŠ” ìœ ì‚¬í•œ í˜ì´ì§€ë¡œ ì—°ê²°ë˜ëŠ” ì±…ë“¤ì´ ì„œë¡œ ìœ ì‚¬í•˜ë‹¤ëŠ” ìƒê°ì„ ë°”íƒ•ìœ¼ë¡œ íš¨ê³¼ì ì¸ ì±… ì¶”ì²œ ì‹œìŠ¤í…œì„ ë§Œë“¤ê¸° ìœ„í•´ ì‹ ê²½ë§ ì„ë² ë”©ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.



ì‹ ê²½ë§ ì„ë² ë”©ì„ í•˜ëŠ” ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì‹ ê²½ë§ì€ ë§ì€ í›ˆë ¨ ë°ì´í„°ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤.
2. ë¬¸ì œë¥¼ ë°˜ì˜í•˜ëŠ” ì„ë² ë”©ì„ ë°°ìš°ê¸° ìœ„í•´ ì§€ë„ í•™ìŠµ ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
3. ì‹ ê²½ë§ ì„ë² ë”© ëª¨ë¸ì„ ë§Œë“¤ê³  í›ˆë ¨ì‹œí‚µë‹ˆë‹¤.
4. ì„ë² ë”© ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ê¶Œì¥ ì‚¬í•­ ë° ì‹œê°í™”í•©ë‹ˆë‹¤.



ìì„¸í•œ ë‚´ìš©ì€ notebookì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë©° ì´ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ì‹œê¸°ë¥¼ ê¶Œí•©ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì€ ê¸°ìˆ ì ì¸ ë³µì¡í•¨ì´ë‚˜ ê³„ì‚°ì  ìì› ë•Œë¬¸ì— ì••ë„ì ìœ¼ë¡œ ë³´ì¼ ìˆ˜ë„ ìˆì§€ë§Œ, ì œí•œëœ ì–‘ì˜ í•™ìŠµìœ¼ë¡œ ê°œì¸ìš© ì»´í“¨í„°ì—ì„œ í•  ìˆ˜ ìˆëŠ” ë§ì€ ì‘ìš© í”„ë¡œê·¸ë¨ë“¤ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì€ ëŠì„ì—†ì´ ë°œì „í•˜ëŠ” ë¶„ì•¼ì´ë©°, ì´ í”„ë¡œì íŠ¸ëŠ” ìœ ìš©í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•¨ìœ¼ë¡œì¨ ì‹œì‘í•˜ëŠ” ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤ë‹¤. ê·¸ë¦¬ê³ , ì—¬ëŸ¬ë¶„ì´ ë”¥ëŸ¬ë‹ì„ ê³µë¶€í•˜ê³  ìˆì§€ ì•ŠëŠ”ë‹¤ë©´, ì—¬ëŸ¬ë¶„ì€ ì§€ê¸ˆ ë¬´ì—‡ì„ ì½ê³  ìˆì–´ì•¼ í•˜ëŠ”ì§€ ì•Œê³  ìˆì–´ìš”! ğŸ˜



> ì´ ê¸€ì€ 2018 ì»¨íŠ¸ë¦¬ë·°í†¤ì—ì„œ [`Contribute to Keras`](https://github.com/KerasKorea/KEKOxTutorial) í”„ë¡œì íŠ¸ë¡œ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.  
>
> Translator: [ë°•ì •í˜„](https://github.com/parkjh688)
>
> Translator email : <parkjh688@gmail.com>
